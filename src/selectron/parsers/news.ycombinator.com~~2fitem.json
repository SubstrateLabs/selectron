{
  "python": "from bs4 import BeautifulSoup\nimport re\n\ndef parse_element(html: str) -> dict:\n    result = {}\n    soup = BeautifulSoup(html, 'html.parser')\n\n    # ID extraction via data- or id attributes\n    id_tag = soup.find(attrs={'data-id': True})\n    if id_tag:\n        result['id'] = id_tag['data-id']\n    else:\n        id_tag = soup.find(attrs={'id': True})\n        if id_tag:\n            result['id'] = id_tag['id']\n\n    # Title extraction from h* or title tags\n    title_tag = None\n    for h in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'title']:\n        title_tag = soup.find(h)\n        if title_tag and title_tag.get_text(strip=True):\n            result['title'] = title_tag.get_text(strip=True)\n            break\n        title_tag = None\n\n    # Primary URL (canonical hyperlink with a <time> tag, or first prominent permalink)\n    primary_url = None\n    for a in soup.find_all('a', href=True):\n        if a.find('time', attrs={'datetime': True}):\n            primary_url = a['href']\n            break\n    if not primary_url:\n        canonical = soup.find('link', rel='canonical')\n        if canonical and canonical.has_attr('href'):\n            primary_url = canonical['href']\n    if not primary_url:\n        a = soup.find('a', href=True)\n        if a:\n            primary_url = a['href']\n    if primary_url:\n        result['primary_url'] = primary_url\n\n    # All other URLs\n    all_urls = set()\n    for a in soup.find_all('a', href=True):\n        if not primary_url or a['href'] != primary_url:\n            all_urls.add(a['href'])\n    if all_urls:\n        result['urls'] = list(all_urls)\n\n    # Author and author URL (look near avatar or by specific classes, else fallback to obvious patterns)\n    author = None\n    author_url = None\n    user_links = soup.find_all('a', href=True)\n    for u in user_links:\n        if 'author' in (u.get('class') or []) or 'user' in (u.get('class') or []):\n            if not author:\n                author = u.get_text(strip=True)\n            if not author_url:\n                author_url = u['href']\n        elif re.search(r'/user/|/author/', u['href']) and not author_url:\n            author_url = u['href']\n    if not author:\n        # Try common selectors\n        author_tag = soup.find(attrs={'data-author': True})\n        if author_tag:\n            author = author_tag['data-author']\n        else:\n            name_candidates = soup.find_all(['span', 'div'], string=True)\n            for c in name_candidates:\n                if re.search(r'^by ', c.get_text(strip=True), re.I):\n                    author = re.sub(r'^by ', '', c.get_text(strip=True), flags=re.I)\n                    break\n    if author:\n        result['author'] = author\n    if author_url:\n        result['author_url'] = author_url\n\n    # Main text description - improve: target .comment, .commtext, .post-body, then fallback\n    description = None\n    descr_selectors = [\n        ('.commtext', None),\n        ('.comment', None),\n        ('.post-body', None),\n        (None, 'article'),\n        (None, 'section'),\n        (None, 'div'),\n    ]\n    for selector, tag in descr_selectors:\n        if selector:\n            cand = soup.select_one(selector)\n        else:\n            cand = soup.find(tag)\n        if cand:\n            # Remove quotes/meta, <font size=\"1\">reply</font> etc inside .reply\n            # Combine only substantial paragraphs\n            p_tags = cand.find_all('p')\n            if p_tags:\n                joined = \" \".join([p.get_text(\" \", strip=True) for p in p_tags if len(p.get_text(strip=True)) > 5])\n                if joined and len(joined) > 20:\n                    description = joined\n                    break\n            else:\n                t = cand.get_text(\" \", strip=True)\n                if t and len(t) > 20:\n                    description = t\n                    break\n    # Fallback to first substantial <p>\n    if not description:\n        for p in soup.find_all('p'):\n            t = p.get_text(\" \", strip=True)\n            if len(t) > 20:\n                description = t\n                break\n    # Remove any trailing 'reply' (common in forum UIs)\n    if description:\n        desc_clean = re.sub(r'\\s*reply\\s*$', '', description, flags=re.I).strip()\n        if desc_clean:\n            result['description'] = desc_clean\n\n    # Images extraction - ignore 1x1 or 0x0 tracking pixels/gifs\n    images = []\n    for img in soup.find_all('img'):\n        src = img.get('src')\n        if not src or src.startswith('data:'):\n            continue\n        width = img.get('width')\n        height = img.get('height')\n        # skip 1x1 or 0x0 images (tracking)\n        if (width and width in ['0', '1']) and (height and height in ['0', '1']):\n            continue\n        img_dict = {'src': src}\n        for attr in ['alt', 'title', 'width', 'height']:\n            val = img.get(attr)\n            if val:\n                img_dict[attr] = val\n        for (k, v) in img.attrs.items():\n            if k.startswith('data-'):\n                img_dict[k] = v\n        images.append(img_dict)\n    if images:\n        result['images'] = images\n\n    # Timestamps: <time> tag\n    time_tag = soup.find('time')\n    if time_tag:\n        dt = time_tag.get('datetime')\n        if dt:\n            result['datetime'] = dt\n        human = time_tag.get_text(strip=True)\n        if human:\n            result['timestamp'] = human\n\n    # Metrics: reply_count, repost_count, like_count, bookmark_count, view_count\n    label_map = {\n        'reply_count': ['reply', 'repl', 'comment'],\n        'repost_count': ['repost', 'retweet', 'reshare'],\n        'like_count': ['like', 'fav', 'heart'],\n        'bookmark_count': ['bookmark'],\n        'view_count': ['view', 'seen'],\n    }\n\n    metric_tags = soup.find_all(['span', 'button', 'div', 'a'])\n    for tag in metric_tags:\n        text = tag.get_text(strip=True).lower()\n        num_match = re.match(r'(\\d[\\d,.]*[km]?)', text)\n        for key, variants in label_map.items():\n            if any(x in text for x in variants):\n                if num_match:\n                    val = num_match.group(1).replace(',', '')\n                    if val.endswith('k'):\n                        mult = 1000\n                        val = val[:-1]\n                    elif val.endswith('m'):\n                        mult = 1000000\n                        val = val[:-1]\n                    else:\n                        mult = 1\n                    try:\n                        ival = int(float(val) * mult)\n                        if key not in result or ival > result.get(key, 0):\n                            result[key] = ival\n                    except Exception:\n                        pass\n\n    # Rank extraction\n    rank_tag = soup.find(attrs={'data-rank': True})\n    if rank_tag:\n        try:\n            rank_val = int(rank_tag['data-rank'])\n            result['rank'] = rank_val\n        except Exception:\n            pass\n\n    # Nested/quoted/embedded content (quoted_author_name, quoted_text, quoted_url)\n    quoted = None\n    quoted_author = None\n    quoted_url = None\n    for div in soup.find_all('div'):\n        if 'quoted' in (div.get('class') or []):\n            quoted_text = div.get_text(\" \", strip=True)\n            if quoted_text:\n                quoted = quoted_text\n            for a in div.find_all('a', href=True):\n                quoted_url = a['href']\n                break\n            author_cand = div.find(['span','div'], string=True)\n            if author_cand:\n                quoted_author = author_cand.get_text(strip=True)\n            break\n    if quoted:\n        result['quoted_text'] = quoted\n    if quoted_author:\n        result['quoted_author_name'] = quoted_author\n    if quoted_url:\n        result['quoted_url'] = quoted_url\n\n    # Remove empty values\n    return {k:v for k,v in result.items() if v not in (None, '', [], {})}",
  "selector": "tr.athing.comtr",
  "selector_description": "all the comments"
}