{
  "python": "from bs4 import BeautifulSoup\nimport re\n\ndef parse_element(html: str) -> dict:\n    result = {}\n    try:\n        soup = BeautifulSoup(html, 'html.parser')\n\n        # Primary URL and id\n        primary_url = None\n        id_candidate = None\n        # Look for <a> with time child as canonical link\n        for a in soup.find_all('a', href=True):\n            if a.find('time', attrs={'datetime': True}):\n                primary_url = a['href']\n                break\n        if not primary_url:\n            canonical_link = soup.find('a', href=True, attrs={'rel': re.compile('canonical', re.I)})\n            if canonical_link:\n                primary_url = canonical_link['href']\n        if not primary_url:\n            # fallback: first valid <a> element\n            first_a = soup.find('a', href=True)\n            if first_a:\n                primary_url = first_a['href']\n        if primary_url:\n            result['primary_url'] = primary_url\n            # Try to get a stable id from the url\n            match = re.search(r'/([A-Za-z0-9_-]{6,})/?$', primary_url)\n            if match:\n                id_candidate = match.group(1)\n        if not id_candidate:\n            # Look for data attributes\n            candidates = [k for k in soup.attrs if k.startswith('data-id')]\n            if candidates:\n                id_candidate = soup.attrs[candidates[0]]\n        if id_candidate:\n            result['id'] = id_candidate\n\n        # Collect all distinct URLs except primary_url\n        urls = []\n        for a in soup.find_all('a', href=True):\n            href = a['href']\n            if primary_url and href == primary_url:\n                continue\n            if href not in urls:\n                urls.append(href)\n        if urls:\n            result['urls'] = urls\n\n        # Title: h1-h6, aria-label, title attribute\n        title = None\n        for i in range(1, 7):\n            h = soup.find(f'h{i}')\n            if h and h.get_text(strip=True):\n                title = h.get_text(strip=True)\n                break\n        if not title:\n            al = soup.find(attrs={'aria-label': True})\n            if al:\n                t = al.get('aria-label', '').strip()\n                if t:\n                    title = t\n        if not title:\n            tag_with_title = soup.find(attrs={'title': True})\n            if tag_with_title:\n                t = tag_with_title.get('title', '').strip()\n                if t:\n                    title = t\n        if title:\n            result['title'] = title\n\n        # Author information\n        author = None\n        author_url = None\n        # Look for data-author, rel=author, near avatar, etc.\n        author_tag = soup.find(attrs={'rel': re.compile('author', re.I)})\n        if author_tag and author_tag.get_text(strip=True):\n            author = author_tag.get_text(strip=True)\n            author_url = author_tag.get('href')\n        else:\n            # Look for class/aria/label containing 'author', 'user', 'profile'\n            author_keyword = re.compile(r'(author|user|profile|by-)', re.I)\n            possible = soup.find(attrs={k: author_keyword for k in ['class', 'id', 'aria-label']})\n            if possible and possible.get_text(strip=True):\n                author = possible.get_text(strip=True)\n                author_url = possible.get('href') if possible.has_attr('href') else None\n        if author:\n            result['author'] = author\n        if author_url:\n            result['author_url'] = author_url\n\n        # Description: main text content, avoid metadata, prefer strong text containers, exclude actions/metadata\n        # Refined: Try to extract company/about/position/summary block, skip 'Apply', timestamp, etc.\n        description = None\n        # Attempt to find main content container logic for listings-like markup\n        main_texts = []\n        container = None\n        # priority: text in the anchor that has the company + tagline\n        if soup.find('a', href=primary_url):\n            a = soup.find('a', href=primary_url)\n            spans = a.find_all('span')\n            for span in spans:\n                text = span.get_text(strip=True)\n                if text and not re.search(r'(\\(S\\d+\\)|\\d+ (days|hours|minutes|months|years) ago|Apply)', text, re.I):\n                    main_texts.append(text)\n        # Next look for the job title/link\n        jobtitle = None\n        job_a = None\n        for a in soup.find_all('a', href=True):\n            # Look for job-related link nearby that is not the main company url\n            if 'job' in a['href'] or 'position' in a['href']:\n                if a.get_text(strip=True) and a['href'] != primary_url:\n                    jobtitle = a.get_text(strip=True)\n                    main_texts.append(jobtitle)\n                    break\n        # Next: summary rows (location, type, etc.)\n        flex_rows = soup.find_all('div', class_=re.compile(r'flex[-_ ]row', re.I))\n        for fr in flex_rows:\n            for d in fr.find_all('div', recursive=False):\n                raw = d.get_text(strip=True)\n                if raw and not re.search(r'(Apply|ago)', raw):\n                    main_texts.append(raw)\n        # Compose description from all fragments\n        if main_texts:\n            description = ' '.join(main_texts)\n        if description:\n            result['description'] = description\n\n        # Images extraction\n        images = []\n        for img in soup.find_all('img', src=True):\n            src = img['src']\n            # Exclude emojis, avatars, data uris\n            if src.startswith('data:') or 'emoji' in src:\n                continue\n            img_dict = {'src': src}\n            if img.get('alt'): img_dict['alt'] = img['alt']\n            if img.get('title'): img_dict['title'] = img['title']\n            if img.get('width'): img_dict['width'] = img['width']\n            if img.get('height'): img_dict['height'] = img['height']\n            # data-* attrs as top-level keys\n            for attr in img.attrs:\n                if attr.startswith('data-'):\n                    img_dict[attr] = img.get(attr)\n            images.append(img_dict)\n        if images:\n            result['images'] = images\n\n        # Times\n        time_tag = soup.find('time')\n        if time_tag:\n            val = time_tag.get('datetime')\n            if val:\n                result['datetime'] = val\n            time_text = time_tag.get_text(strip=True)\n            if time_text:\n                result['timestamp'] = time_text\n\n        # Metrics\n        def parse_metric(val):\n            if not val:\n                return None\n            val = val.strip().replace(',', '')\n            m = re.match(r'([0-9.]+)([KkMm]?)', val)\n            if m:\n                num, suf = m.groups()\n                f = float(num)\n                if suf in ['K', 'k']:\n                    f *= 1_000\n                elif suf in ['M', 'm']:\n                    f *= 1_000_000\n                return int(f)\n            try:\n                return int(val)\n            except Exception:\n                return None\n\n        metric_map = {\n            'reply_count': ['reply', 'comment'],\n            'repost_count': ['repost', 'retweet', 'share'],\n            'like_count': ['like', 'heart', 'fav'],\n            'bookmark_count': ['bookmark'],\n            'view_count': ['view', 'impression'],\n        }\n        for metric, keys in metric_map.items():\n            patt = re.compile(r'(?:' + '|'.join(keys) + r')', re.I)\n            found = None\n            for t in soup.find_all(True):\n                for att in ['alt', 'title', 'aria-label', 'data-testid', 'class', 'id']:\n                    v = t.get(att)\n                    if v and patt.search(str(v)):\n                        text = t.get_text(strip=True)\n                        val = parse_metric(text)\n                        if val is not None:\n                            found = val\n                            break\n                if found is not None:\n                    break\n            if found is not None:\n                result[metric] = found\n\n        # Ranking/position\n        for attr in ['data-rank', 'data-pos', 'data-rank-index']:\n            rank = soup.attrs.get(attr)\n            if rank:\n                try:\n                    rank_val = int(rank)\n                    result['rank'] = rank_val\n                    break\n                except Exception:\n                    continue\n    except Exception:\n        pass\n\n    return result",
  "selector": "ul.space-y-2.overflow-hidden > li.bg-beige-lighter",
  "selector_description": "All job listing cards in the main job feed displaying job title, company name, location, job type, and application button"
}